# Drivable Space ViT Configuration

# Model architecture parameters
model:
  img_size: 224           # Input image size for ViT
  patch_size: 16          # Patch size for ViT
  num_channels: 3         # RGB images
  embed_dim: 768          # Embedding dimension
  num_heads: 12           # Number of attention heads
  num_layers: 12          # Number of transformer layers
  mlp_ratio: 4            # Expansion ratio for MLP
  dropout: 0.1            # Dropout probability
  attn_dropout: 0.1       # Attention dropout probability
  ego_motion_dim: 6       # Ego motion dimensions (speed, acceleration, steering, etc.)

# Dataset parameters
dataset:
  seq_len: 5              # Number of frames in sequence
  batch_size: 16          # Batch size for training
  num_workers: 8          # Number of worker processes for data loading
  random_sequence: true   # Randomly select starting frame in sequence during training
  cache_images: false     # Whether to cache images in memory

# Training parameters
training:
  epochs: 100             # Number of epochs to train
  lr: 1e-4                # Learning rate
  weight_decay: 1e-4      # Weight decay
  warmup_epochs: 10       # Number of warmup epochs
  min_lr: 1e-6            # Minimum learning rate
  reconstruction_weight: 1.0  # Weight for reconstruction loss
  consistency_weight: 1.0     # Weight for consistency loss
  future_weight: 0.5          # Weight for future prediction loss
  mixed_precision: false      # Whether to use mixed precision training
  gradient_accumulation: 1    # Number of gradient accumulation steps

# Logging and saving parameters
logging:
  log_interval: 10        # Logging interval in steps
  save_interval: 5        # Checkpoint saving interval in epochs
  eval_interval: 1        # Evaluation interval in epochs
  visualize_every: 5      # Visualize predictions every N epochs
  num_viz_samples: 10     # Number of samples to visualize 