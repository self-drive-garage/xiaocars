# Drivable Space ViT Configuration

# Model architecture parameters
model:
  img_size: 224           # Input image size for ViT
  patch_size: 16          # Patch size for ViT
  num_channels: 3         # RGB images
  embed_dim: 768          # Embedding dimension
  num_heads: 12           # Number of attention heads
  num_layers: 12          # Number of transformer layers
  mlp_ratio: 4            # Expansion ratio for MLP
  dropout: 0.1            # Dropout probability
  attn_dropout: 0.1       # Attention dropout probability
  ego_motion_dim: 15      # Updated: 3(translation) + 3(rotation) + 3(velocity) + 3(acceleration) + 3(angular_velocity)

# Dataset parameters
dataset:
  seq_len: 3              # Number of frames used by the model for one sample
  batch_size: 16          # Batch size for training
  num_workers: 8          # Number of worker processes for data loading
  random_sequence: true   # Enable random sequence sampling for training
  cache_images: false     # Whether to cache images in memory
  temporal:
    stride: 1             # Number of frames to skip between sequences
    overlap: 0            # Number of overlapping frames between sequences
    max_gap: 0.15         # Maximum allowed time gap between consecutive frames (in seconds)
                          # 0.15s allows for some variation from the expected 0.1s (10Hz)
    log_handling:
      min_log_frames: 10  # Minimum frames required in a log
      max_log_frames: 1000  # Maximum frames to use from a log
    validation:
      stride: 5           # Larger stride for validation
      max_gap: 0.12       # Stricter gap requirement for validation (closer to 10Hz)

# Training parameters
training:
  epochs: 100             # Number of epochs to train
  lr: 1e-4                # Learning rate
  weight_decay: 1e-4      # Weight decay
  warmup_epochs: 10       # Number of warmup epochs
  min_lr: 1e-6            # Minimum learning rate
  reconstruction_weight: 1.0  # Weight for reconstruction loss
  consistency_weight: 1.0     # Weight for consistency loss
  future_weight: 0.5          # Weight for future prediction loss
  temporal_weight: 0.3        # New: Weight for temporal consistency loss
  mixed_precision: false      # Whether to use mixed precision training
  gradient_accumulation: 1    # Number of gradient accumulation steps

# Logging and saving parameters
logging:
  log_interval: 10        # Logging interval in steps
  save_interval: 5        # Checkpoint saving interval in epochs
  eval_interval: 1        # Evaluation interval in epochs
  visualize_every: 5      # Visualize predictions every N epochs
  num_viz_samples: 10     # Number of samples to visualize
  visualize_sequences: true  # New: Whether to visualize temporal sequences 